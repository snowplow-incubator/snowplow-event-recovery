name: Release

on:
  push:
    tags:
      - '*'
jobs:
  release:
    if: "!contains(github.event.head_commit.message, 'skip ci')"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout project
        uses: actions/checkout@v2
      - name: Setup Scala
        uses: olafurpg/setup-scala@v10
      - name: Build core
        run: |
          sbt core/assembly
      - name: Build beam
        run: |
          sbt "beam/docker:publishLocal;beam/universal:packageBin"
      - name: Build spark
        run: |
          sbt spark/assembly
      - name: Build flink
        run: |
          sbt flink/assembly
      - name: Build cli
        run: |
          sbt cli/assembly
      - name: Deploy hosted-assets
        env:
          TAG: ${{github.ref_name}}
          BUCKET: snowplow-hosted-assets
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          aws --region="eu-west-1" s3 cp spark/target/scala-2.12/snowplow-event-recovery-spark-$TAG.jar s3://$BUCKET/3-enrich/snowplow-event-recovery/snowplow-event-recovery-spark-$TAG.jar
          aws --region="eu-west-1" s3 cp spark/emr/bootstrap-java-11.sh s3://$BUCKET/3-enrich/snowplow-event-recovery/emr-bootstrap-java-11.sh
          for aws_region in "us-east-1" "us-west-1" "us-west-2" "sa-east-1" "eu-central-1" "ap-southeast-1" "ap-southeast-2" "ap-northeast-1" "ap-south-1" "us-east-2" "ca-central-1" "eu-west-2" "ap-northeast-2"; do aws --region="${aws_region}" s3 cp spark/target/scala-2.12/snowplow-event-recovery-spark-$TAG.jar s3://$BUCKET-${aws_region}/3-enrich/snowplow-event-recovery/snowplow-event-recovery-spark-$TAG.jar && aws --region="eu-west-1" s3 cp spark/emr/bootstrap-java-11.sh s3://$BUCKET/3-enrich/snowplow-event-recovery/emr-bootstrap-java-11.sh; done
          aws --region="eu-west-1" s3 cp flink/target/scala-2.12/snowplow-event-recovery-flink-$TAG.jar s3://$BUCKET/3-enrich/snowplow-event-recovery/snowplow-event-recovery-flink-$TAG.jar
          aws --region="eu-west-1" s3 cp .dataflow-runner/bootstrap.sh s3://$BUCKET/3-enrich/snowplow-event-recovery/snowplow-event-recovery-flink-$TAG-bootstrap.sh
          for aws_region in "us-east-1" "us-west-1" "us-west-2" "sa-east-1" "eu-central-1" "ap-southeast-1" "ap-southeast-2" "ap-northeast-1" "ap-south-1" "us-east-2" "ca-central-1" "eu-west-2" "ap-northeast-2"; do aws --region="${aws_region}" s3 cp flink/target/scala-2.12/snowplow-event-recovery-flink-$TAG.jar s3://$BUCKET-${aws_region}/3-enrich/snowplow-event-recovery/snowplow-event-recovery-flink-$TAG.jar && aws --region="eu-west-1" s3 cp .dataflow-runner/bootstrap.sh s3://$BUCKET/3-enrich/snowplow-event-recovery/snowplow-event-recovery-flink-$TAG-bootstrap.sh; done
      - name: Docker login
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      - name: Publish Docker
        env:
          REPOSITORY: snowplow/snowplow-event-recovery-beam
          TAG: ${{github.ref_name}}
        run: docker push $REPOSITORY:$TAG
      - name: Create GH release
        uses: softprops/action-gh-release@v1
        if: startsWith(github.ref, 'refs/tags/')
        with:
          body: ${{ env.CHANGELOG }}
          draft: true
          name: Version ${{github.ref_name}}
          tag_name: ${{github.ref_name}}
          files: |
            beam/target/universal/snowplow-event-recovery-beam-${{github.ref_name}}.zip
            spark/target/scala-2.12/snowplow-event-recovery-spark-${{github.ref_name}}.jar
            flink/target/scala-2.12/snowplow-event-recovery-flink-${{github.ref_name}}.jar
            cli/target/scala-2.12/snowplow-event-recovery
